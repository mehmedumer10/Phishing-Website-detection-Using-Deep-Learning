# -*- coding: utf-8 -*-
"""Code_Machine_Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fQVanH3T2l6Kns43JehpvGx8hUDYXLAW

## Installing the required packages
"""

pip install squarify

"""## Importing the required packages"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC
import joblib
from sklearn.ensemble import VotingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
# %matplotlib inline

df = pd.read_csv("phishing_data.csv")

df.head()

df.shape

df.describe()

df.info()

# Check for null values
null_values = df.isnull().sum()

# Display the count of null values in each column
print(null_values)

df['status'].value_counts()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
df.hist(bins=50, figsize=(20,15))

"""## Data preprocessing"""

pd.set_option('display.max_rows', 100)
df.isna().sum()

# Load the dataset
df = pd.read_csv('phishing_data.csv')

# Display the dataset before deleting the column
print("Dataset before deleting a column:")
df.head()

# Delete a column
column_to_delete = 'url'
df.drop(column_to_delete, axis=1, inplace=True)

# Display the dataset after deleting the column
print("\nDataset after deleting the column:")
df.head()

"""## Converting categorical values into numeric values"""

# Set display options
pd.set_option('display.max_rows', 100)

# Convert target variable to numeric format
classes = {'legitimate': 0, 'phishing': 1}
df['status'] = df['status'].map(classes)

# Exclude non-numeric columns from correlation analysis
numeric_df = df.select_dtypes(include='number')

# Calculate the correlation matrix
corr_matrix = numeric_df.corr()

# Reset display options
pd.reset_option('display.max_rows')

# Plot the correlation matrix
plt.figure(figsize=(60, 60))
color = plt.get_cmap('viridis').copy()
color.set_bad('lightblue')
sns.heatmap(corr_matrix, annot=True, linewidth=0.4, cmap=color)
plt.savefig('heatmap')
plt.show()

corr_matrix['status']

"""## Plotting 3 dimensional plot"""

import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Extract the relevant columns for the plot
x = df['length_url']
y = df['length_hostname']
z = df['status']

# Create a 3D plot
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

# Scatter plot
ax.scatter(x, y, z, c='blue', marker='o')

# Connect the points with lines
ax.plot(x, y, z, c='red', linestyle='--')

# Set labels for the axes
ax.set_xlabel('length_url')
ax.set_ylabel('length_hostname')
ax.set_zlabel('status')

# Set the title of the plot
ax.set_title('Three-Dimensional Plot')

# Show the plot
plt.show()

status_corr = corr_matrix['status']
status_corr.shape

def feature_selector_correlation(cmatrix, threshold):

    selected_features = []
    feature_score = []
    i=0
    for score in cmatrix:
        if abs(score)>threshold:
            selected_features.append(cmatrix.index[i])
            feature_score.append( ['{:3f}'.format(score)])
        i+=1
    result = list(zip(selected_features,feature_score))
    return result

"""## Features selection"""

features_selected = feature_selector_correlation(status_corr, 0.2)
features_selected

"""## Plotting Treemap of selected features"""

import seaborn as sns
import matplotlib.pyplot as plt
import squarify

# Create a dictionary to store the feature names and their correlation values
feature_data = {
    feature: float(value[0])
    for feature, value in features_selected
}

# Convert the dictionary to a list of tuples sorted by correlation values
sorted_data = sorted(feature_data.items(), key=lambda x: x[1], reverse=True)

# Extract the feature names and correlation values
labels = [item[0] for item in sorted_data]
values = [item[1] for item in sorted_data]

# Calculate the sizes for the treemap squares
sizes = [abs(value) for value in values]

# Set the color scheme for the treemap
cmap = 'viridis' if min(values) >= 0 else 'RdBu_r'

# Convert the colormap to a list of colors
colors = sns.color_palette(cmap, len(labels))

# Create the treemap plot
plt.figure(figsize=(10, 8))
squarify.plot(sizes=sizes, label=labels, color=colors, alpha=0.8)

# Set the title and axis labels using seaborn style
plt.title('Treemap of Correlated Features')
plt.axis('off')

# Save the plot as an image
plt.savefig('treemap.png', bbox_inches='tight')

# Show the plot
plt.show()

selected_features = [i for (i,j) in features_selected if i != 'status']
selected_features

X= df[selected_features]
X

y = df['status']
y

"""## Split the data into train and test sets"""

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,shuffle=True)

"""## Model Building and training"""

# Create instances of the classifiers
svc = SVC(kernel='linear', C=1.0)
rfc = RandomForestClassifier()
dtc = DecisionTreeClassifier()
# List of classifiers
classifiers = [svc, rfc, dtc]

# Create instances of the classifiers
svc = SVC(kernel='linear', C=0.1)  # Adjust the C parameter for regularization
dtc = DecisionTreeClassifier()
rfc = RandomForestClassifier()

# Combine classifiers using VotingClassifier
classifiers = [
    ('SVC', svc),
    ('DecisionTreeClassifie', dtc),
    ('RandomForestClassifier', rfc),
]

voting_classifier = VotingClassifier(classifiers, voting='hard')

# Train the voting classifier on the training data
voting_classifier.fit(X_train, y_train)

# Perform cross-validation
cv_scores = cross_val_score(voting_classifier, X_train, y_train, cv=5)

# Calculate mean accuracy and standard deviation
mean_accuracy = cv_scores.mean()
std_accuracy = cv_scores.std()

# Print the results
print(f"Voting Classifier Cross-Validation Mean Accuracy: {mean_accuracy:.4f}")
print(f"Voting Classifier Cross-Validation Standard Deviation: {std_accuracy:.4f}")

# Evaluate the voting classifier on the test data
test_accuracy = voting_classifier.score(X_test, y_test)
print(f"Voting Classifier Accuracy on Test Set: {test_accuracy:.4f}")

"""## Evaluating the model on test data"""

from sklearn.metrics import precision_recall_fscore_support
# Make predictions on the test set
y_pred = voting_classifier.predict(X_test)

# Calculate precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')

# Print the precision, recall, and F1-score
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1_score:.4f}")

# Make predictions on the test set
y_pred = voting_classifier.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Legitimate', 'Phishing'], yticklabels=['Legitimate', 'Phishing'])

# Add labels, title, and axis ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png', bbox_inches='tight')
plt.show()

# Save the trained voting_classifier model
joblib.dump(voting_classifier, '1st_model.joblib')

# Load the saved model
loaded_voting_classifier = joblib.load('1st_model.joblib')

adaboost = AdaBoostClassifier()
knn = KNeighborsClassifier()
lr = LogisticRegression(max_iter=1000)  # Increase max_iter to 1000

# List of classifiers
classifiers = [adaboost, knn, lr]

# Create instances of the classifiers
adaboost = AdaBoostClassifier()
knn = KNeighborsClassifier()
lr = LogisticRegression(max_iter=1000)  # Increase max_iter to 1000
# Combine classifiers using VotingClassifier
classifiers = [
    ('adaboost', adaboost),
    ('KNeighborsClassifier', knn),
    ('LogisticRegression', lr),
]

voting_classifier = VotingClassifier(classifiers, voting='hard')

# Train the voting classifier on the training data
voting_classifier.fit(X_train, y_train)

# Perform cross-validation
cv_scores = cross_val_score(voting_classifier, X_train, y_train, cv=5)

# Calculate mean accuracy and standard deviation
mean_accuracy = cv_scores.mean()
std_accuracy = cv_scores.std()

# Print the results
print(f"Voting Classifier Cross-Validation Mean Accuracy: {mean_accuracy:.4f}")
print(f"Voting Classifier Cross-Validation Standard Deviation: {std_accuracy:.4f}")

# Evaluate the voting classifier on the test data
test_accuracy = voting_classifier.score(X_test, y_test)
print(f"Voting Classifier Accuracy on Test Set: {test_accuracy:.4f}")

"""## Evaluating the model on test data"""

from sklearn.metrics import precision_recall_fscore_support
# Make predictions on the test set
y_pred = voting_classifier.predict(X_test)

# Calculate precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')

# Print the precision, recall, and F1-score
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1_score:.4f}")

# Plot the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Create a heatmap
plt.figure(figsize=(6, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)

# Add labels, title, and axis ticks
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.xticks(np.arange(2), ['Legitimate', 'Phishing'], rotation=45)
plt.yticks(np.arange(2), ['Legitimate', 'Phishing'], rotation=0)
# Save the plot as an image
plt.savefig('confusion_matrix2.png', bbox_inches='tight')

plt.show()

# Save the trained voting_classifier model
joblib.dump(voting_classifier, '2nd_model.joblib')

# Load the saved model
#loaded_voting_classifier = joblib.load('2nd_model.joblib')

"""Models Comparison"""

import seaborn as sns
import matplotlib.pyplot as plt

# Define the classifiers and their corresponding evaluation metrics
classifiers = [
    "Ensebmle SVC,DTC and RFC with Voting Algorithm",
    "Ensebmle Adaboost,KNN and LRC with Voting Algorithm",
    "Decision Tree",
    "Random Forest Classisfier"

]
mean_accuracy = [0.9750, 0.9468, 0.95, 0.9714]
std_accuracy = [0.0046, 0.0036, 0.0039, 0.0047]
accuracy_scores = [0.9751, 0.9468, 0.95, 0.9714]
precision_scores = [0.9730, 0.9473, 0.9421, 0.9312]
recall_scores = [0.9730, 0.94736, 0.9421, 0.9312]
f1_scores = [0.9730, 0.94736, 0.9421, 0.9312]

# Create a DataFrame for the evaluation metrics
data = {
    "Classifier": classifiers,
    "Accuracy": accuracy_scores,
    "Precision": precision_scores,
    "Recall": recall_scores,
    "F1-Score": f1_scores
}
df = pd.DataFrame(data)

# Set the style and plot the bar graph
sns.set(style="whitegrid")
plt.figure(figsize=(8, 5))
sns.barplot(x="Classifier", y="Accuracy", data=df)

# Set labels and title
plt.xlabel("Classifier")
plt.ylabel("Accuracy")
plt.title("Classifier Performance - Accuracy")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Save the plot as an image
plt.savefig('Comparison With Other Models.png', bbox_inches='tight')

# Show the plot
plt.show()

